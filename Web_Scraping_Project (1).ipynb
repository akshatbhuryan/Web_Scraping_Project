{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMLqV/6+CyjPytphlnzSSOV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **Problem Statement: Navigating the Data Science Job Landscape**\n","\n","üöÄ Unleash your creativity in crafting a solution that taps into the heartbeat of the data science job market! Envision an ingenious project that seamlessly wields cutting-edge web scraping techniques and illuminating data analysis.\n","\n","üîç Your mission? To engineer a tool that effortlessly gathers job listings from a multitude of online sources, extracting pivotal nuggets such as job descriptions, qualifications, locations, and salaries.\n","\n","üß© However, the true puzzle lies in deciphering this trove of data. Can your solution discern patterns that spotlight the most coveted skills? Are there threads connecting job types to compensation packages? How might it predict shifts in industry demand?\n","\n","üéØ The core objectives of this challenge are as follows:\n","\n","1. Web Scraping Mastery: Forge an adaptable and potent web scraping mechanism. Your creation should adeptly harvest data science job postings from a diverse array of online platforms. Be ready to navigate evolving website structures and process hefty data loads.\n","\n","2. Data Symphony: Skillfully distill vital insights from the harvested job listings. Extract and cleanse critical information like job titles, company names, descriptions, qualifications, salaries, locations, and deadlines. Think data refinement and organization.\n","\n","3. Market Wizardry: Conjure up analytical tools that conjure meaningful revelations from the gathered data. Dive into the abyss of job demand trends, geographic distribution, salary variations tied to experience and location, favored qualifications, and emerging skill demands.\n","\n","4. Visual Magic: Weave a tapestry of visualization magic. Design captivating charts, graphs, and visual representations that paint a crystal-clear picture of the analyzed data. Make these visuals the compass that guides users through job market intricacies.\n","\n","üåê While the web scraping universe is yours to explore, consider these platforms as potential stomping grounds:\n","\n","* LinkedIn Jobs\n","* Indeed\n","* Naukri\n","* Glassdoor\n","* AngelList\n","\n","üéà Your solution should not only decode the data science job realm but also empower professionals, job seekers, and recruiters to harness the dynamic shifts of the industry. The path is open, the challenge beckons ‚Äì are you ready to embark on this exciting journey?\n","\n","\n","\n","\n"],"metadata":{"id":"1gmsTnWj-tIp"}},{"cell_type":"markdown","source":["## **Github Link- [link text](https://github.com/akshatbhuryan/Web_Scraping_Project)**"],"metadata":{"id":"VRN5y8iP_KKv"}},{"cell_type":"code","source":["import requests\n","import bs4\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time"],"metadata":{"id":"JaXsPzoS5VVE","executionInfo":{"status":"ok","timestamp":1709412403837,"user_tz":-330,"elapsed":470,"user":{"displayName":"Akshat Bhuryan","userId":"15761017736029503739"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["URL = \"https://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n","#conducting a request of the stated URL above:\n","page = requests.get(URL)\n","#specifying the desired format of \"page\" using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\n","soup = BeautifulSoup(page.text, \"html.parser\")\n","#printing soup in a more structured tree format that makes for easier reading\n","print(soup.prettify())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nvT3SSFZ6502","executionInfo":{"status":"ok","timestamp":1709413192050,"user_tz":-330,"elapsed":421,"user":{"displayName":"Akshat Bhuryan","userId":"15761017736029503739"}},"outputId":"aef3a5c4-4363-4358-d2a3-6857e59a84a1"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["<!DOCTYPE html>\n","<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n","<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n","<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\n","<!--[if gt IE 8]><!-->\n","<html class=\"no-js\" lang=\"en-US\">\n"," <!--<![endif]-->\n"," <head>\n","  <title>\n","   Attention Required! | Cloudflare\n","  </title>\n","  <meta charset=\"utf-8\"/>\n","  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n","  <meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/>\n","  <meta content=\"noindex, nofollow\" name=\"robots\"/>\n","  <meta content=\"width=device-width,initial-scale=1\" name=\"viewport\"/>\n","  <link href=\"/cdn-cgi/styles/cf.errors.css\" id=\"cf_styles-css\" rel=\"stylesheet\"/>\n","  <!--[if lt IE 9]><link rel=\"stylesheet\" id='cf_styles-ie-css' href=\"/cdn-cgi/styles/cf.errors.ie.css\" /><![endif]-->\n","  <style>\n","   body{margin:0;padding:0}\n","  </style>\n","  <!--[if gte IE 10]><!-->\n","  <script>\n","   if (!navigator.cookieEnabled) {\n","    window.addEventListener('DOMContentLoaded', function () {\n","      var cookieEl = document.getElementById('cookie-alert');\n","      cookieEl.style.display = 'block';\n","    })\n","  }\n","  </script>\n","  <!--<![endif]-->\n"," </head>\n"," <body>\n","  <div id=\"cf-wrapper\">\n","   <div class=\"cf-alert cf-alert-error cf-cookie-error\" data-translate=\"enable_cookies\" id=\"cookie-alert\">\n","    Please enable cookies.\n","   </div>\n","   <div class=\"cf-error-details-wrapper\" id=\"cf-error-details\">\n","    <div class=\"cf-wrapper cf-header cf-error-overview\">\n","     <h1 data-translate=\"block_headline\">\n","      Sorry, you have been blocked\n","     </h1>\n","     <h2 class=\"cf-subheadline\">\n","      <span data-translate=\"unable_to_access\">\n","       You are unable to access\n","      </span>\n","      indeed.com\n","     </h2>\n","    </div>\n","    <!-- /.header -->\n","    <div class=\"cf-section cf-highlight\">\n","     <div class=\"cf-wrapper\">\n","      <div class=\"cf-screenshot-container cf-screenshot-full\">\n","       <span class=\"cf-no-screenshot error\">\n","       </span>\n","      </div>\n","     </div>\n","    </div>\n","    <!-- /.captcha-container -->\n","    <div class=\"cf-section cf-wrapper\">\n","     <div class=\"cf-columns two\">\n","      <div class=\"cf-column\">\n","       <h2 data-translate=\"blocked_why_headline\">\n","        Why have I been blocked?\n","       </h2>\n","       <p data-translate=\"blocked_why_detail\">\n","        This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data.\n","       </p>\n","      </div>\n","      <div class=\"cf-column\">\n","       <h2 data-translate=\"blocked_resolve_headline\">\n","        What can I do to resolve this?\n","       </h2>\n","       <p data-translate=\"blocked_resolve_detail\">\n","        You can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page.\n","       </p>\n","      </div>\n","     </div>\n","    </div>\n","    <!-- /.section -->\n","    <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n","     <p class=\"text-13\">\n","      <span class=\"cf-footer-item sm:block sm:mb-1\">\n","       Cloudflare Ray ID:\n","       <strong class=\"font-semibold\">\n","        85e4501f8cba17ff\n","       </strong>\n","      </span>\n","      <span class=\"cf-footer-separator sm:hidden\">\n","       ‚Ä¢\n","      </span>\n","      <span class=\"cf-footer-item hidden sm:block sm:mb-1\" id=\"cf-footer-item-ip\">\n","       Your IP:\n","       <button class=\"cf-footer-ip-reveal-btn\" id=\"cf-footer-ip-reveal\" type=\"button\">\n","        Click to reveal\n","       </button>\n","       <span class=\"hidden\" id=\"cf-footer-ip\">\n","        35.243.200.7\n","       </span>\n","       <span class=\"cf-footer-separator sm:hidden\">\n","        ‚Ä¢\n","       </span>\n","      </span>\n","      <span class=\"cf-footer-item sm:block sm:mb-1\">\n","       <span>\n","        Performance &amp; security by\n","       </span>\n","       <a href=\"https://www.cloudflare.com/5xx-error-landing\" id=\"brand_link\" rel=\"noopener noreferrer\" target=\"_blank\">\n","        Cloudflare\n","       </a>\n","      </span>\n","     </p>\n","     <script>\n","      (function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();\n","     </script>\n","    </div>\n","    <!-- /.error-footer -->\n","   </div>\n","   <!-- /#cf-error-details -->\n","  </div>\n","  <!-- /#cf-wrapper -->\n","  <script>\n","   window._cf_translation = {};\n","  </script>\n"," </body>\n","</html>\n","\n"]}]},{"cell_type":"markdown","source":["## **Getting Job Title**\n","As can be seen, the entirety of each job posting is under <div> tags, with an attribute ‚Äúclass‚Äù = ‚Äúrow result.‚Äù\n","\n","Further, we could also see that job titles are under <a> tags, with the attribute ‚Äútitle = (title)‚Äù. One can see the value of the tag‚Äôs attribute with tag[‚Äúattribute‚Äù], so I can use it to find each posting‚Äôs job title.\n","\n","If we summarize, the function we are going to see involves the following three steps,\n","\n","Pulling out all the <div> tags with class including ‚Äúrow‚Äù.\n","Identifying <a> tags with attribute ‚Äúdata-tn-element‚Äù:‚ÄùjobTitle‚Äù\n","For each of these <a> tags, find attribute values ‚Äútitle‚Äù"],"metadata":{"id":"dGU6TqcS83wm"}},{"cell_type":"code","source":["def extract_job_title_from_result(soup):\n","  jobs = []\n","  for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n","    for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n","      jobs.append(a[\"title\"])\n","  return(jobs)\n","extract_job_title_from_result(soup)\n","\n"],"metadata":{"id":"LHWb5bHx67pn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Getting Company Name**\n","Getting company names can be a bit tricky because most of them are appearing in <span> tags, with ‚Äúclass‚Äù:‚Äù company‚Äù.  They are also housed in <span> tags with ‚Äúclass‚Äù:‚Äù result-link-source‚Äù.\n","\n","We will be using if/else statements to extract the company info from each of these places. In order to remove the white spaces around the company names when they are outputted, we will use inputting.strip() at the end."],"metadata":{"id":"ZuJaOJ7o99gm"}},{"cell_type":"code","source":["def extract_company_from_result(soup):\n"," companies = []\n"," for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n","   company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n","   if len(company) > 0:\n","    for b in company:\n","     companies.append(b.text.strip())\n","   else:\n","    sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n","    for span in sec_try:\n","      companies.append(span.text.strip())\n"," return(companies)\n","\n","extract_company_from_result(soup)"],"metadata":{"id":"6MQLI6kK6_df"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Getting Location**\n","Locations are located under the <span> tags. Span tags are sometimes nested within each other, such that the location text may sometimes be within ‚Äúclass‚Äù:‚Äùlocation‚Äù attributes, or nested in ‚Äúitemprop‚Äù:‚ÄùaddressLocality‚Äù. However a simple for loop can examine all span tags for text and retrieve the necessary information."],"metadata":{"id":"WIH10KZT-HkE"}},{"cell_type":"code","source":["def extract_location_from_result(soup):\n","  locations = []\n","  spans = soup.findAll('span', attrs={'class': 'location'})\n","  for span in spans:\n","    locations.append(span.text)\n","  return(locations)\n","extract_location_from_result(soup)"],"metadata":{"id":"UhyKLzkp7HuT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Getting Salary**\n","Salary is the most challenging part to extract from job postings. Most postings don‚Äôt publish salary information at all, while others that do, there can be multiple places to pick that. So we have to write a code that can pick up multiple salaries from multiple places, and if no salary is found, we need to create a placeholder ‚ÄúNothing Found‚Äù value for any jobs that don‚Äôt contain salary.\n","\n","Some salaries are under <nobr> tags, while others are under <div> tags, ‚Äúclass‚Äù:‚Äùsjcl‚Äù and are under separate div tags with no attributes. Try/except statement can be helpful while extracting this information."],"metadata":{"id":"zSYd9ene-OGp"}},{"cell_type":"code","source":["def extract_salary_from_result(soup):\n","  salaries = []\n","  for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n","    try:\n","      salaries.append(div.find('nobr').text)\n","    except:\n","      try:\n","        div_two = div.find(name=\"div\", attrs={\"class\":\"sjcl\"})\n","        div_three = div_two.find(\"div\")\n","        salaries.append(div_three.text.strip())\n","      except:\n","        salaries.append(\"Nothing_found\")\n","  return(salaries)\n","extract_salary_from_result(soup)"],"metadata":{"id":"B-2yvHkx-WFp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Getting Job Summary**\n","The final job is to get the job summary. However, it is not possible to get the job summaries for each particular position because they are not included in the HTML from a given Indeed page. We can get some information about each job from what‚Äôs provided. We can use Selenium for this purpose.\n","\n","But let‚Äôs first try this using python. Summaries are located under <span> tags. Span tags are nested within each other such that the location text is within ‚Äúclass‚Äù:‚Äù location‚Äù tags or nested in ‚Äúitemprop‚Äù:‚Äù adressLocality‚Äù. However, using a simple for loop can examine all span tags for text to retrieve the necessary information."],"metadata":{"id":"IzKKoUsh-j2S"}}]}